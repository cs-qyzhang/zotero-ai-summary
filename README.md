# LLM Paper Summarizer for Zotero

在 Zotero 中使用 LLM 自动总结论文并生成笔记。

Automatically summarize academic papers and generate notes in Zotero using an LLM.

工作流程：以 [zotero-actions-tags](https://github.com/windingwind/zotero-actions-tags) 脚本的形式实现。在 zotero 中新增论文时，zotero-actions-tags 触发 JavaScript 脚本，获取论文的 PDF 文件地址和论文名，并调用 python 脚本生成论文总结。在 python 脚本中，使用 langchain 对 PDF 解析并分割（pypdf），之后调用 LLM API 总结论文，最后将总结写入到文件中。JavaScript 脚本等待 python 脚本执行完后从文件中读取总结，并生成 zotero 笔记。

Workflow: this tool is implemented as a script for [zotero-actions-tags](https://github.com/windingwind/zotero-actions-tags). When a new paper is added to Zotero, the zotero-actions-tags plugin triggers a JavaScript script to retrieve the PDF file path and paper title. It then calls a Python script to generate the paper summary. The Python script uses LangChain to parse and split the PDF (via pypdf), invokes an LLM API to create a summary, and saves the summary to a file. Once the Python script completes, the JavaScript script reads the summary from the file and creates a note in Zotero.

![example](https://qyzhang-obsidian.oss-cn-hangzhou.aliyuncs.com/20250124100826.png)

## Setup

### Python Setup

```bash
conda create -n zotero-ai-summary python=3.12
conda activate zotero-ai-summary
git clone https://github.com/cs-qyzhang/zotero-ai-summary.git
cd zotero-ai-summary
pip install -r ./requirements.txt
```

### Zotero Setup

安装 [zotero-actions-tags](https://github.com/windingwind/zotero-actions-tags) 插件，并按照下图配置。

Install the [zotero-actions-tags](https://github.com/windingwind/zotero-actions-tags) plugin and configure it as shown below:

![zotero-actions-tags settings](https://qyzhang-obsidian.oss-cn-hangzhou.aliyuncs.com/20250124094839.png)

![edit action](https://qyzhang-obsidian.oss-cn-hangzhou.aliyuncs.com/20250124095407.png)

## Configuration

在 `zotero_script.js` 代码的顶端包含了一些配置，如下所示。

At the beginning of the `zotero_script.js` file, you’ll find some configurable options:

```js
const project_dir = "C:\\Users\\qyzhang\\project\\zotero-ai-summary";
const python_exe = "C:\\Users\\qyzhang\\miniconda3\\envs\\zotero-ai-summary\\python.exe";
const pythonScript = `${project_dir}\\paper_summary.py`;
const only_link_file = true;
const timeout = 30;
```

- `project_dir`：`git clone` 后的项目地址
- `python_exe`：conda 环境中的 python 地址
- `only_link_file`：配合 [ZotMoov](https://github.com/wileyyugioh/zotmoov) 或 [ZotFile](https://github.com/jlegewie/zotfile) 使用。如果使用这两个或类似的插件将论文 PDF 以 Zotero 的 "Link to File" 形式保存，则应设置 `only_link_file` 为 `true`，否则设置为 `false`。
- `timeout`：配合 [ZotMoov](https://github.com/wileyyugioh/zotmoov) 或 [ZotFile](https://github.com/jlegewie/zotfile) 使用。在新增论文时，最多等待多少秒后检查 PDF 是否下载完成。

<br>

- `project_dir`: The directory where the repository was cloned.
- `python_exe`: The path to the Python executable in the Conda environment.
- `only_link_file`: Set this to `true` if you manage PDFs as "Link to File" using  - [ZotMoov](https://github.com/wileyyugioh/zotmoov) or [ZotFile](https://github.com/jlegewie/zotfile). Otherwise, set it to `false`.
- `timeout`: Used in conjunction with [ZotMoov](https://github.com/wileyyugioh/zotmoov) or [ZotFile](https://github.com/jlegewie/zotfile). Specifies the maximum number of seconds to wait after adding a paper to check if the PDF download is complete.

### LLM API

在想用的大模型提供商（ChatGPT/Qwen/DeepSeek...）充钱并获取 OpenAI 兼容的 API key。编辑 `~/.config/llm.json` 文件（以下为 DeepSeek 示例）：

Sign up with your preferred LLM provider (e.g., ChatGPT, Claude, DeepSeek) to obtain an OpenAI-compatible API key, then create or edit the `~/.config/llm.json` file. Below is an example for DeepSeek:

```json
{
  "name": "deekseek-v3",
  "model": "deepseek-chat",
  "base_url": "https://api.deepseek.com/v1",
  "api_key": "sk-xxxxxxxxx",
  "context_length": 64000
}
```

其中的 `name` 是在总结笔记中显示的模型名，`model` 是真正的模型名。

`name` is the model name displayed in the summary note, and `model` is the actual model name.

### LLM Prompt

默认使用的总结提示词是由 ChatGPT-o1 生成的英文提示词。可以修改 `stuff_prompt.txt`、`map_prompt.txt` 和 `reduce_prompt.txt` 三个文件来自定义提示词。

By default, English summarization prompts generated by ChatGPT-o1 are used. You can customize these prompts by modifying the `stuff_prompt.txt`, `map_prompt.txt`, and `reduce_prompt.txt` files.

如果论文字符数小于模型的上下文长度，则使用 `stuff_prompt.txt` 将论文内容一次性输入获取总结；否则将论文分割为多个 chunk，对于每一个 chunk 先使用 `map_prompt.txt` 生成单个 chunk 的总结，最后使用 `reduce_prompt.txt` 合并每个 chunk 总结并生成最终的总结。

If the paper's content fits within the model's context length, the `stuff_prompt.txt` file is used to process it all at once. For longer papers exceed model's context length, the content is split into chunks. Each chunk is summarized using the `map_prompt.txt` prompt, and the chunk summaries are combined using the `reduce_prompt.txt` prompt to create the final summary.
